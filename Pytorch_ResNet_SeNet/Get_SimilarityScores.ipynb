{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "from io import open\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "import models.resnet as ResNet\n",
    "import models.senet as SENet\n",
    "\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import resnet, resnet50_ferplus_dag, resnet50_ft_dag, resnet50_scratch_dag, senet, senet50_ferplus_dag, senet50_ft_dag, senet50_scratch_dag, vgg_face_dag, vgg_m_face_bn_dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvarela\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Senet50_scratch_dag(\n",
       "  (conv1_7x7_s2): Conv2d(3, 64, kernel_size=[7, 7], stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_relu_7x7_s2): ReLU()\n",
       "  (pool1_3x3_s2): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=(0, 0), dilation=1, ceil_mode=True)\n",
       "  (conv2_1_1x1_reduce): Conv2d(64, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv2_1_1x1_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_1_1x1_reduce_relu): ReLU()\n",
       "  (conv2_1_3x3): Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv2_1_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_1_3x3_relu): ReLU()\n",
       "  (conv2_1_1x1_increase): Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv2_1_1x1_increase_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_1_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv2_1_1x1_down): Conv2d(256, 16, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv2_1_1x1_down_relu): ReLU()\n",
       "  (conv2_1_1x1_up): Conv2d(16, 256, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv2_1_prob): Sigmoid()\n",
       "  (conv2_1_1x1_proj): Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv2_1_1x1_proj_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_1_relu): ReLU()\n",
       "  (conv2_2_1x1_reduce): Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv2_2_1x1_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_2_1x1_reduce_relu): ReLU()\n",
       "  (conv2_2_3x3): Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv2_2_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_2_3x3_relu): ReLU()\n",
       "  (conv2_2_1x1_increase): Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv2_2_1x1_increase_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_2_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv2_2_1x1_down): Conv2d(256, 16, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv2_2_1x1_down_relu): ReLU()\n",
       "  (conv2_2_1x1_up): Conv2d(16, 256, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv2_2_prob): Sigmoid()\n",
       "  (conv2_2_relu): ReLU()\n",
       "  (conv2_3_1x1_reduce): Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv2_3_1x1_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_3_1x1_reduce_relu): ReLU()\n",
       "  (conv2_3_3x3): Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv2_3_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_3_3x3_relu): ReLU()\n",
       "  (conv2_3_1x1_increase): Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv2_3_1x1_increase_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_3_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv2_3_1x1_down): Conv2d(256, 16, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv2_3_1x1_down_relu): ReLU()\n",
       "  (conv2_3_1x1_up): Conv2d(16, 256, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv2_3_prob): Sigmoid()\n",
       "  (conv2_3_relu): ReLU()\n",
       "  (conv3_1_1x1_reduce): Conv2d(256, 128, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
       "  (conv3_1_1x1_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_1_1x1_reduce_relu): ReLU()\n",
       "  (conv3_1_3x3): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv3_1_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_1_3x3_relu): ReLU()\n",
       "  (conv3_1_1x1_increase): Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv3_1_1x1_increase_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_1_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv3_1_1x1_down): Conv2d(512, 32, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv3_1_1x1_down_relu): ReLU()\n",
       "  (conv3_1_1x1_up): Conv2d(32, 512, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv3_1_prob): Sigmoid()\n",
       "  (conv3_1_1x1_proj): Conv2d(256, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
       "  (conv3_1_1x1_proj_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_1_relu): ReLU()\n",
       "  (conv3_2_1x1_reduce): Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv3_2_1x1_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_2_1x1_reduce_relu): ReLU()\n",
       "  (conv3_2_3x3): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv3_2_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_2_3x3_relu): ReLU()\n",
       "  (conv3_2_1x1_increase): Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv3_2_1x1_increase_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_2_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv3_2_1x1_down): Conv2d(512, 32, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv3_2_1x1_down_relu): ReLU()\n",
       "  (conv3_2_1x1_up): Conv2d(32, 512, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv3_2_prob): Sigmoid()\n",
       "  (conv3_2_relu): ReLU()\n",
       "  (conv3_3_1x1_reduce): Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv3_3_1x1_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_3_1x1_reduce_relu): ReLU()\n",
       "  (conv3_3_3x3): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv3_3_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_3_3x3_relu): ReLU()\n",
       "  (conv3_3_1x1_increase): Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv3_3_1x1_increase_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_3_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv3_3_1x1_down): Conv2d(512, 32, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv3_3_1x1_down_relu): ReLU()\n",
       "  (conv3_3_1x1_up): Conv2d(32, 512, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv3_3_prob): Sigmoid()\n",
       "  (conv3_3_relu): ReLU()\n",
       "  (conv3_4_1x1_reduce): Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv3_4_1x1_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_4_1x1_reduce_relu): ReLU()\n",
       "  (conv3_4_3x3): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv3_4_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_4_3x3_relu): ReLU()\n",
       "  (conv3_4_1x1_increase): Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv3_4_1x1_increase_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_4_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv3_4_1x1_down): Conv2d(512, 32, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv3_4_1x1_down_relu): ReLU()\n",
       "  (conv3_4_1x1_up): Conv2d(32, 512, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv3_4_prob): Sigmoid()\n",
       "  (conv3_4_relu): ReLU()\n",
       "  (conv4_1_1x1_reduce): Conv2d(512, 256, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
       "  (conv4_1_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_1_1x1_reduce_relu): ReLU()\n",
       "  (conv4_1_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv4_1_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_1_3x3_relu): ReLU()\n",
       "  (conv4_1_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_1_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_1_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv4_1_1x1_down): Conv2d(1024, 64, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_1_1x1_down_relu): ReLU()\n",
       "  (conv4_1_1x1_up): Conv2d(64, 1024, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_1_prob): Sigmoid()\n",
       "  (conv4_1_1x1_proj): Conv2d(512, 1024, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
       "  (conv4_1_1x1_proj_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_1_relu): ReLU()\n",
       "  (conv4_2_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_2_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_2_1x1_reduce_relu): ReLU()\n",
       "  (conv4_2_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv4_2_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_2_3x3_relu): ReLU()\n",
       "  (conv4_2_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_2_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_2_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv4_2_1x1_down): Conv2d(1024, 64, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_2_1x1_down_relu): ReLU()\n",
       "  (conv4_2_1x1_up): Conv2d(64, 1024, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_2_prob): Sigmoid()\n",
       "  (conv4_2_relu): ReLU()\n",
       "  (conv4_3_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_3_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_3_1x1_reduce_relu): ReLU()\n",
       "  (conv4_3_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv4_3_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_3_3x3_relu): ReLU()\n",
       "  (conv4_3_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_3_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_3_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv4_3_1x1_down): Conv2d(1024, 64, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_3_1x1_down_relu): ReLU()\n",
       "  (conv4_3_1x1_up): Conv2d(64, 1024, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_3_prob): Sigmoid()\n",
       "  (conv4_3_relu): ReLU()\n",
       "  (conv4_4_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_4_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_4_1x1_reduce_relu): ReLU()\n",
       "  (conv4_4_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv4_4_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_4_3x3_relu): ReLU()\n",
       "  (conv4_4_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_4_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_4_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv4_4_1x1_down): Conv2d(1024, 64, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_4_1x1_down_relu): ReLU()\n",
       "  (conv4_4_1x1_up): Conv2d(64, 1024, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_4_prob): Sigmoid()\n",
       "  (conv4_4_relu): ReLU()\n",
       "  (conv4_5_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_5_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_5_1x1_reduce_relu): ReLU()\n",
       "  (conv4_5_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv4_5_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_5_3x3_relu): ReLU()\n",
       "  (conv4_5_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_5_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_5_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv4_5_1x1_down): Conv2d(1024, 64, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_5_1x1_down_relu): ReLU()\n",
       "  (conv4_5_1x1_up): Conv2d(64, 1024, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_5_prob): Sigmoid()\n",
       "  (conv4_5_relu): ReLU()\n",
       "  (conv4_6_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_6_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_6_1x1_reduce_relu): ReLU()\n",
       "  (conv4_6_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv4_6_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_6_3x3_relu): ReLU()\n",
       "  (conv4_6_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv4_6_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_6_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv4_6_1x1_down): Conv2d(1024, 64, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_6_1x1_down_relu): ReLU()\n",
       "  (conv4_6_1x1_up): Conv2d(64, 1024, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv4_6_prob): Sigmoid()\n",
       "  (conv4_6_relu): ReLU()\n",
       "  (conv5_1_1x1_reduce): Conv2d(1024, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
       "  (conv5_1_1x1_reduce_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_1_1x1_reduce_relu): ReLU()\n",
       "  (conv5_1_3x3): Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv5_1_3x3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_1_3x3_relu): ReLU()\n",
       "  (conv5_1_1x1_increase): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv5_1_1x1_increase_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_1_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv5_1_1x1_down): Conv2d(2048, 128, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv5_1_1x1_down_relu): ReLU()\n",
       "  (conv5_1_1x1_up): Conv2d(128, 2048, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv5_1_prob): Sigmoid()\n",
       "  (conv5_1_1x1_proj): Conv2d(1024, 2048, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
       "  (conv5_1_1x1_proj_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_1_relu): ReLU()\n",
       "  (conv5_2_1x1_reduce): Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv5_2_1x1_reduce_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_2_1x1_reduce_relu): ReLU()\n",
       "  (conv5_2_3x3): Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv5_2_3x3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_2_3x3_relu): ReLU()\n",
       "  (conv5_2_1x1_increase): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv5_2_1x1_increase_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_2_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv5_2_1x1_down): Conv2d(2048, 128, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv5_2_1x1_down_relu): ReLU()\n",
       "  (conv5_2_1x1_up): Conv2d(128, 2048, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv5_2_prob): Sigmoid()\n",
       "  (conv5_2_relu): ReLU()\n",
       "  (conv5_3_1x1_reduce): Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv5_3_1x1_reduce_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_3_1x1_reduce_relu): ReLU()\n",
       "  (conv5_3_3x3): Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv5_3_3x3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_3_3x3_relu): ReLU()\n",
       "  (conv5_3_1x1_increase): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
       "  (conv5_3_1x1_increase_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_3_global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv5_3_1x1_down): Conv2d(2048, 128, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv5_3_1x1_down_relu): ReLU()\n",
       "  (conv5_3_1x1_up): Conv2d(128, 2048, kernel_size=[1, 1], stride=(1, 1))\n",
       "  (conv5_3_prob): Sigmoid()\n",
       "  (conv5_3_relu): ReLU()\n",
       "  (pool5_7x7_s1): AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n",
       "  (classifier): Conv2d(2048, 8631, kernel_size=[1, 1], stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "############  CHOOSE HERE WHICH ALGORITHM YOU WANT: #################\n",
    "\n",
    "# model = resnet50_ft_dag.resnet50_ft_dag(weights_path='Weights/resnet50_ft_dag.pth')\n",
    "# SaveAs = 'ResNet50_MS1M_'\n",
    "\n",
    "\n",
    "# model = resnet50_scratch_dag.resnet50_scratch_dag(weights_path='Weights/resnet50_scratch_dag.pth')\n",
    "# SaveAs = 'ResNet50_VggFace2_'\n",
    "\n",
    "# model = senet50_ft_dag.senet50_ft_dag(weights_path='Weights/senet50_ft_dag.pth')\n",
    "# SaveAs = 'SeNet50_MS1M_'\n",
    "\n",
    "model = senet50_scratch_dag.senet50_scratch_dag(weights_path='Weights/senet50_scratch_dag.pth')\n",
    "# SaveAs = 'SeNet50_VggFace2_'\n",
    "\n",
    "######################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = transforms.Scale((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get List of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../General_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Euclidean Distance of penultimal Layers between pairs of faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunModel(img_url_1,img_url_2):\n",
    "    \n",
    "    imagepath = img_url_1\n",
    "    image = Image.open(imagepath)\n",
    "    imgblob = Variable(normalize(to_tensor(image)).unsqueeze(0))\n",
    "    output1 = model(imgblob)\n",
    "    output1 = output1[1].flatten()\n",
    "    \n",
    "        \n",
    "        \n",
    "    imagepath = img_url_2\n",
    "    image = Image.open(imagepath)\n",
    "    imgblob = Variable(normalize(to_tensor(image)).unsqueeze(0))\n",
    "    output2 = model(imgblob)\n",
    "    output2 = output2[1].flatten()\n",
    "        \n",
    "    \n",
    "\n",
    "    dist = np.linalg.norm(output1.detach().numpy()-output2.detach().numpy())\n",
    "#     print(dist)\n",
    "    \n",
    "    return(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_result=[]\n",
    "for i in range(len(df)):\n",
    "    print(i)\n",
    "    model_result.append(RunModel('../Database/CroppedFoveated224x224/'+df.FoveatedImages[i],'../Database/CroppedOriginal224x224/'+df.SecondImage[i]+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92607296\n",
      "1.3288354\n",
      "0.401677\n",
      "0.38230446\n",
      "2.2213838\n",
      "0.37414157\n",
      "1.5078299\n",
      "1.5174578\n",
      "1.9805298\n",
      "1.5024135\n",
      "1.3282284\n",
      "0.8072483\n",
      "0.8609411\n",
      "1.0549909\n",
      "1.0592362\n",
      "0.29613125\n",
      "0.78866976\n",
      "1.4782957\n",
      "0.5733741\n",
      "0.57980967\n",
      "1.5643952\n",
      "2.0317402\n",
      "1.5631489\n",
      "0.5532105\n",
      "1.5384302\n",
      "0.632857\n",
      "1.1466771\n",
      "0.452086\n",
      "0.37314752\n",
      "0.90810144\n",
      "1.4765406\n",
      "0.8064004\n",
      "1.327221\n",
      "0.57312006\n",
      "1.5707434\n",
      "1.037357\n",
      "1.0168679\n",
      "0.50823975\n",
      "1.1597557\n",
      "1.4709729\n",
      "0.6166363\n",
      "0.32812607\n",
      "0.5780072\n",
      "0.9766302\n",
      "1.2790979\n",
      "1.1610193\n",
      "0.37704384\n",
      "1.5672094\n",
      "0.8079962\n",
      "0.84766585\n",
      "0.56638116\n",
      "1.3289706\n",
      "0.99215215\n",
      "1.4524702\n",
      "0.5676026\n",
      "0.88863945\n",
      "1.0610626\n",
      "0.95921725\n",
      "1.5635784\n",
      "1.4954185\n",
      "0.6070736\n",
      "1.0742111\n",
      "0.9857569\n",
      "0.30784723\n",
      "1.5451715\n",
      "2.1917665\n",
      "2.3177266\n",
      "1.5688097\n",
      "2.2174282\n",
      "1.3227959\n",
      "1.4500117\n",
      "0.85960805\n",
      "1.1592308\n",
      "0.4328739\n",
      "1.3197185\n",
      "1.5513755\n",
      "1.5356269\n",
      "0.58489245\n",
      "2.243604\n",
      "1.453443\n",
      "0.7830933\n",
      "0.5505293\n",
      "1.3778774\n",
      "0.3630473\n",
      "1.5356824\n",
      "1.0596107\n",
      "1.083109\n",
      "1.327596\n",
      "1.0839436\n",
      "0.4724662\n",
      "0.32617462\n",
      "1.1630361\n",
      "1.5041052\n",
      "0.92651355\n",
      "0.88968956\n",
      "1.5734429\n",
      "0.4070151\n",
      "0.79006636\n",
      "1.5517412\n",
      "1.150449\n",
      "0.60595065\n",
      "0.91091007\n",
      "1.0042467\n",
      "1.4712266\n",
      "1.3410226\n",
      "1.3271563\n",
      "0.26927385\n",
      "0.849167\n",
      "1.0735128\n",
      "2.2159605\n",
      "1.0594282\n",
      "1.5051349\n",
      "1.6034343\n",
      "1.1684898\n",
      "0.59272057\n",
      "1.5518829\n",
      "1.0546058\n",
      "1.172212\n",
      "1.4951754\n",
      "1.4827948\n",
      "1.1275682\n",
      "0.84071916\n",
      "0.56873035\n",
      "0.88953286\n",
      "0.94429725\n",
      "0.6447369\n",
      "1.0742145\n",
      "0.9831974\n",
      "2.20519\n",
      "0.5829182\n",
      "1.052068\n",
      "0.5879183\n",
      "1.5829831\n",
      "0.4055226\n",
      "2.2467759\n",
      "1.4538336\n",
      "1.158574\n",
      "1.363175\n",
      "1.4238623\n",
      "1.3709401\n",
      "1.5599837\n",
      "0.17907989\n",
      "0.2847741\n",
      "0.4150117\n",
      "0.9385238\n",
      "2.166668\n",
      "2.1989157\n",
      "1.4878498\n",
      "0.27593428\n",
      "0.82747287\n",
      "1.1590003\n",
      "1.0624977\n",
      "2.213749\n",
      "1.2020652\n",
      "1.6086701\n",
      "1.5731475\n",
      "0.86180604\n",
      "0.94505125\n",
      "1.4333723\n",
      "1.1616501\n",
      "1.687295\n",
      "1.5488144\n",
      "0.332713\n",
      "1.1543938\n",
      "1.5850022\n",
      "1.5101656\n",
      "1.1615971\n",
      "1.334192\n",
      "0.78053176\n",
      "0.36257038\n",
      "1.454715\n",
      "0.99222195\n",
      "1.5414437\n",
      "1.1644093\n",
      "1.1663779\n",
      "1.3395518\n",
      "2.2089891\n",
      "2.20567\n",
      "0.30775207\n",
      "1.0557892\n",
      "0.9578322\n",
      "0.9272196\n",
      "1.2022313\n",
      "1.1837\n",
      "1.4358784\n",
      "1.0501845\n",
      "0.4646348\n",
      "0.28756377\n",
      "0.51910293\n",
      "0.903909\n",
      "0.9744901\n",
      "0.61273515\n",
      "1.3205619\n",
      "1.1913394\n",
      "0.3628742\n",
      "0.578074\n",
      "1.0611211\n",
      "1.3407927\n",
      "0.4174105\n",
      "2.2547495\n",
      "0.30660605\n",
      "0.4519511\n",
      "1.1933395\n",
      "0.7843382\n",
      "0.40076077\n",
      "1.3830596\n",
      "2.234858\n",
      "1.4372572\n",
      "0.94912505\n",
      "1.4293048\n",
      "0.30417466\n",
      "0.58313096\n",
      "0.5762359\n",
      "0.79642385\n",
      "1.4887912\n",
      "0.6631306\n",
      "1.6168729\n",
      "1.5147773\n",
      "1.4993861\n",
      "2.22037\n",
      "1.5838485\n",
      "1.1381141\n",
      "0.38067114\n",
      "0.3649707\n",
      "1.4576027\n",
      "1.2695735\n",
      "0.84932256\n",
      "0.22788867\n",
      "1.5642734\n",
      "0.37384197\n",
      "1.552952\n",
      "0.7901197\n",
      "2.2064114\n",
      "0.34967342\n",
      "0.6019918\n",
      "0.4380784\n",
      "1.537008\n",
      "0.97514373\n",
      "1.1996424\n",
      "0.94500285\n",
      "0.875022\n",
      "1.48071\n",
      "1.4676493\n",
      "0.62387246\n",
      "0.6112824\n",
      "0.80131567\n",
      "2.2420397\n",
      "1.1181849\n",
      "1.1600237\n",
      "0.62123877\n",
      "1.3219317\n",
      "0.30041665\n",
      "1.0966558\n",
      "0.29899743\n",
      "1.5813928\n",
      "1.1874952\n",
      "0.9367195\n",
      "1.4719782\n",
      "1.4587092\n",
      "0.85102755\n",
      "1.0465808\n",
      "0.5883466\n",
      "0.2728002\n",
      "1.3394437\n",
      "0.83264536\n",
      "0.5812807\n",
      "0.93919003\n",
      "0.34526184\n",
      "1.4655617\n",
      "0.3142993\n",
      "1.0634241\n",
      "0.5693904\n",
      "0.31729576\n",
      "0.6466561\n",
      "1.5986519\n",
      "1.5924666\n",
      "0.5935094\n",
      "1.5103126\n",
      "1.4692928\n",
      "2.2085516\n",
      "0.84086317\n",
      "0.57808036\n",
      "0.6288674\n",
      "0.34323904\n",
      "2.2166638\n",
      "1.4555343\n",
      "1.5729879\n",
      "0.5928774\n",
      "1.5159515\n",
      "1.2742573\n",
      "0.8575933\n",
      "1.351926\n",
      "1.5803732\n",
      "0.79112893\n",
      "0.3396348\n",
      "1.0685817\n",
      "1.4181383\n",
      "0.78102785\n",
      "1.3267524\n",
      "0.5850477\n",
      "0.29400948\n",
      "0.800216\n",
      "0.90967673\n",
      "1.4425637\n",
      "1.1556036\n",
      "1.5356019\n",
      "0.38090453\n",
      "2.2090456\n",
      "1.4710237\n",
      "0.41933936\n",
      "1.548786\n",
      "1.3628969\n",
      "0.57385594\n",
      "1.1760302\n",
      "1.1525965\n",
      "1.5197724\n",
      "1.509957\n",
      "0.30237925\n",
      "0.5957374\n",
      "1.0730934\n",
      "0.95226187\n",
      "0.8249903\n",
      "1.0789175\n",
      "1.3308412\n",
      "0.9131269\n",
      "0.81934017\n",
      "1.5099425\n",
      "2.2144659\n",
      "1.6185681\n",
      "0.91551375\n",
      "2.2214196\n",
      "1.0617871\n",
      "0.9864715\n",
      "1.3273231\n",
      "1.0662397\n",
      "2.196901\n",
      "1.3344215\n",
      "0.8837644\n",
      "1.4777453\n",
      "0.89859325\n",
      "1.0524546\n",
      "1.3321133\n",
      "1.5322878\n",
      "2.2046907\n",
      "0.7875186\n",
      "2.2130816\n",
      "1.43562\n",
      "0.93015015\n",
      "1.3871577\n",
      "0.4367224\n",
      "1.3319837\n",
      "1.1575246\n",
      "1.0574243\n",
      "0.5801946\n",
      "1.4527065\n",
      "2.2383823\n",
      "0.90632105\n",
      "1.562381\n",
      "1.0764577\n",
      "0.29688594\n",
      "1.5546128\n",
      "1.1305997\n",
      "0.25261784\n",
      "0.7919099\n",
      "0.9973543\n",
      "2.2159948\n",
      "1.1611377\n",
      "1.5723007\n",
      "1.5213611\n",
      "0.47447428\n",
      "0.63914305\n",
      "1.3428694\n",
      "0.60283643\n",
      "1.6289551\n",
      "1.1324904\n",
      "1.0648476\n",
      "1.0799661\n",
      "0.5963541\n",
      "1.4754015\n",
      "0.93228126\n",
      "2.2102523\n",
      "1.1581087\n",
      "1.5440508\n",
      "0.32372105\n",
      "1.1720072\n",
      "1.3382623\n",
      "2.2055948\n",
      "1.3098016\n",
      "1.3435719\n",
      "0.3113611\n",
      "0.32504454\n",
      "1.3442423\n",
      "1.0658485\n",
      "1.4365501\n",
      "0.96354014\n",
      "1.3305494\n",
      "1.0557767\n",
      "1.5581759\n",
      "1.4118247\n",
      "1.0362295\n",
      "0.5817595\n",
      "0.3239462\n",
      "2.2350287\n",
      "1.0710338\n",
      "1.1569253\n",
      "1.1669241\n",
      "2.2183042\n",
      "0.93640107\n",
      "1.4750953\n",
      "2.2574775\n",
      "0.9506664\n",
      "0.34479156\n",
      "1.3274935\n",
      "0.42965344\n",
      "1.5400953\n",
      "0.42628196\n",
      "1.3302728\n",
      "0.87172127\n",
      "0.9431647\n",
      "1.5263015\n",
      "1.0451298\n",
      "1.5139141\n",
      "1.4812092\n",
      "0.7956177\n",
      "1.4989289\n",
      "0.80158454\n",
      "1.584177\n",
      "1.2057769\n",
      "1.4412603\n",
      "1.4987613\n",
      "0.8273178\n",
      "0.3064743\n",
      "0.4116879\n",
      "1.4280472\n",
      "0.54787403\n",
      "1.5354435\n",
      "0.3175461\n",
      "1.2055274\n",
      "0.5815748\n",
      "2.2106829\n",
      "0.31357387\n",
      "0.5743348\n",
      "1.0769666\n",
      "1.6044487\n",
      "1.0638973\n",
      "0.40025216\n",
      "0.31129038\n",
      "1.573377\n",
      "1.3915259\n",
      "1.0076199\n",
      "0.5786588\n",
      "0.81671524\n",
      "0.83934176\n",
      "0.9865321\n",
      "1.4659374\n",
      "1.2143543\n",
      "0.59888166\n",
      "0.5711429\n",
      "0.57621497\n",
      "1.067585\n",
      "0.9757326\n",
      "0.58338434\n",
      "0.5228917\n",
      "0.7433745\n",
      "0.8034526\n",
      "1.1541295\n",
      "1.3749543\n",
      "1.5619463\n",
      "1.4964386\n",
      "1.1629779\n",
      "1.4745039\n",
      "0.36998326\n",
      "2.2068865\n",
      "1.4479127\n",
      "1.4486318\n",
      "0.84481984\n",
      "0.29184306\n",
      "0.57691723\n",
      "0.7956594\n",
      "0.387756\n",
      "1.451055\n",
      "1.5412774\n",
      "1.58388\n",
      "2.2230587\n",
      "0.7339877\n",
      "1.186478\n",
      "0.44913322\n",
      "0.45026654\n",
      "1.2813536\n",
      "0.39670384\n",
      "1.4462973\n",
      "1.3997713\n",
      "1.2609391\n",
      "1.453365\n",
      "1.1792252\n",
      "0.59033483\n",
      "0.64606047\n",
      "1.029747\n",
      "1.0395474\n",
      "0.30157453\n",
      "0.5726378\n",
      "0.9076153\n",
      "0.537206\n",
      "0.5421173\n",
      "1.4654883\n",
      "1.412337\n",
      "1.5083023\n",
      "0.6132719\n",
      "1.4786893\n",
      "0.56191504\n",
      "0.48203668\n",
      "0.5178293\n",
      "0.38178056\n",
      "0.7261505\n",
      "0.91040915\n",
      "0.59381646\n",
      "1.1968371\n",
      "0.63213825\n",
      "1.4573138\n",
      "1.0250746\n",
      "1.4141204\n",
      "0.57038295\n",
      "1.6245983\n",
      "0.90026724\n",
      "0.58087325\n",
      "0.33498412\n",
      "0.5433367\n",
      "0.80436546\n",
      "1.1490427\n",
      "0.49381068\n",
      "0.44494173\n",
      "1.4373093\n",
      "0.59225833\n",
      "0.6295417\n",
      "0.62660146\n",
      "1.1885192\n",
      "1.3453399\n",
      "0.87936556\n",
      "0.5325706\n",
      "0.71429294\n",
      "1.0420861\n",
      "0.8220141\n",
      "1.5067933\n",
      "1.4436804\n",
      "0.57505107\n",
      "1.0412956\n",
      "0.7884372\n",
      "0.3136486\n",
      "1.4343454\n",
      "1.2573615\n",
      "1.1518487\n",
      "1.5119045\n",
      "1.2810227\n",
      "1.1771965\n",
      "1.1808168\n",
      "0.64526784\n",
      "0.48753816\n",
      "0.37262997\n",
      "1.1790503\n",
      "1.435506\n",
      "1.430667\n",
      "0.54874486\n",
      "1.2926353\n",
      "1.1186762\n",
      "0.5662135\n",
      "0.5169548\n",
      "1.231139\n",
      "0.3710421\n",
      "1.473825\n",
      "1.0365251\n",
      "1.0730588\n",
      "1.1920552\n",
      "0.42227325\n",
      "0.5347774\n",
      "0.39172575\n",
      "0.49387124\n",
      "0.93152976\n",
      "0.7376549\n",
      "0.7202153\n",
      "1.5166948\n",
      "0.4170322\n",
      "0.5737439\n",
      "1.4439578\n",
      "0.4773131\n",
      "0.5724092\n",
      "0.7209089\n",
      "0.82414734\n",
      "0.9021353\n",
      "1.1911899\n",
      "1.1829193\n",
      "0.27277943\n",
      "0.631538\n",
      "1.0408739\n",
      "1.2662703\n",
      "1.0270816\n",
      "1.4525156\n",
      "1.4915175\n",
      "0.50047046\n",
      "0.65105164\n",
      "1.4419811\n",
      "1.5994655\n",
      "0.5050003\n",
      "1.3870244\n",
      "1.4246053\n",
      "1.1046295\n",
      "0.62986\n",
      "0.5309691\n",
      "0.72008497\n",
      "0.6794192\n",
      "0.61248344\n",
      "1.0418943\n",
      "0.7904241\n",
      "1.2907388\n",
      "0.4743019\n",
      "1.0220927\n",
      "0.5547169\n",
      "1.5202546\n",
      "0.2668755\n",
      "1.2955598\n",
      "0.8840483\n",
      "0.49114034\n",
      "1.2120122\n",
      "1.6234553\n",
      "1.2280605\n",
      "1.4472793\n",
      "0.23650688\n",
      "0.2902871\n",
      "0.4585951\n",
      "0.76338\n",
      "1.2188748\n",
      "1.2801021\n",
      "0.91700166\n",
      "0.28106606\n",
      "0.7019354\n",
      "0.49417236\n",
      "1.0396221\n",
      "1.2679855\n",
      "1.3002558\n",
      "1.5700649\n",
      "1.458668\n",
      "0.6458443\n",
      "0.77590376\n",
      "0.8629835\n",
      "0.4970766\n",
      "1.6372193\n",
      "0.8936736\n",
      "0.33843765\n",
      "0.48416078\n",
      "1.4687746\n",
      "1.4601486\n",
      "0.4963916\n",
      "1.9805975\n",
      "0.56558126\n",
      "0.37090716\n",
      "0.8831606\n",
      "1.3945651\n",
      "1.4175268\n",
      "0.4957804\n",
      "0.49519494\n",
      "1.1912485\n",
      "1.289501\n",
      "1.2891324\n",
      "0.37887886\n",
      "1.0254861\n",
      "0.697154\n",
      "0.72853905\n",
      "1.6625378\n",
      "1.3273349\n",
      "0.8581178\n",
      "1.0180018\n",
      "0.7735615\n",
      "0.29204383\n",
      "0.57364047\n",
      "0.7214032\n",
      "1.325843\n",
      "0.57979035\n",
      "1.184394\n",
      "1.1925901\n",
      "0.37341163\n",
      "0.5453528\n",
      "1.0515641\n",
      "1.1925374\n",
      "0.36844066\n",
      "1.3123068\n",
      "0.31027752\n",
      "0.5175363\n",
      "0.54684556\n",
      "1.4999825\n",
      "0.40221196\n",
      "1.235107\n",
      "1.3115622\n",
      "0.8677487\n",
      "0.77597916\n",
      "0.84785223\n",
      "0.3072559\n",
      "0.6415417\n",
      "0.5409169\n",
      "0.5789687\n",
      "0.918863\n",
      "0.8129812\n",
      "1.5553311\n",
      "1.1809733\n",
      "1.3978548\n",
      "1.3069891\n",
      "1.5287629\n",
      "0.903828\n",
      "0.44856474\n",
      "0.37369087\n",
      "0.8800734\n",
      "1.6372325\n",
      "0.6342017\n",
      "0.26979628\n",
      "1.5145221\n",
      "0.44259763\n",
      "1.4371284\n",
      "0.57201546\n",
      "1.2724005\n",
      "0.35787073\n",
      "0.65613735\n",
      "0.50366056\n",
      "1.4809315\n",
      "0.7221731\n",
      "0.5315551\n",
      "0.75330395\n",
      "0.92799556\n",
      "0.91098607\n",
      "0.8923859\n",
      "0.50859624\n",
      "0.5783166\n",
      "0.5868164\n",
      "1.3127712\n",
      "1.6580107\n",
      "0.49201524\n",
      "0.5898017\n",
      "1.1761955\n",
      "0.30721727\n",
      "1.1034645\n",
      "0.30460516\n",
      "1.5195082\n",
      "0.5408759\n",
      "0.76840657\n",
      "0.8954161\n",
      "0.8850806\n",
      "0.63652104\n",
      "1.0205332\n",
      "0.64664185\n",
      "0.27758908\n",
      "1.1905898\n",
      "0.61735636\n",
      "0.6396112\n",
      "0.7541342\n",
      "0.35515642\n",
      "1.40827\n",
      "0.31773454\n",
      "1.0475769\n",
      "0.53467345\n",
      "0.32343924\n",
      "0.61488247\n",
      "1.480363\n",
      "1.5306331\n",
      "0.5576771\n",
      "1.39866\n",
      "0.9027338\n",
      "1.2720888\n",
      "0.6240045\n",
      "0.54246396\n",
      "0.5976515\n",
      "0.35028383\n",
      "1.2716589\n",
      "0.8813286\n",
      "1.459084\n",
      "0.5587357\n",
      "1.4559358\n",
      "0.74870706\n",
      "0.9457723\n",
      "1.202535\n",
      "1.5249697\n",
      "0.5728187\n",
      "0.34700072\n",
      "1.0359775\n",
      "0.83748585\n",
      "0.56560165\n",
      "1.1889821\n",
      "0.54867256\n",
      "0.29999912\n",
      "0.5842519\n",
      "0.7334736\n",
      "0.8618623\n",
      "0.48329905\n",
      "1.4887512\n",
      "0.4488646\n",
      "1.2860776\n",
      "0.89987427\n",
      "0.48663116\n",
      "1.4331367\n",
      "1.2095432\n",
      "0.5362072\n",
      "0.51482934\n",
      "0.48718685\n",
      "1.4021403\n",
      "1.3967623\n",
      "0.30872583\n",
      "0.5602705\n",
      "1.0541596\n",
      "0.7520164\n",
      "0.60563356\n",
      "1.0478185\n",
      "1.1952057\n",
      "0.7413955\n",
      "0.52030426\n",
      "1.4558461\n",
      "1.2814482\n",
      "1.5900027\n",
      "0.717965\n",
      "1.2810297\n",
      "1.0295787\n",
      "0.7933137\n",
      "1.1906135\n",
      "1.043961\n",
      "1.2601565\n",
      "1.1987374\n",
      "0.7114518\n",
      "1.3790647\n",
      "0.6867878\n",
      "1.0222965\n",
      "1.1893348\n",
      "1.4737188\n",
      "1.2868953\n",
      "0.5727191\n",
      "1.2645419\n",
      "1.3821172\n",
      "0.76154643\n",
      "1.2264419\n",
      "0.37472853\n",
      "1.1898068\n",
      "0.49134004\n",
      "1.0325891\n",
      "0.54714847\n",
      "0.8763918\n",
      "1.2915933\n",
      "0.7340644\n",
      "1.4504721\n",
      "1.0429982\n",
      "0.30220187\n",
      "1.4448717\n",
      "0.482177\n",
      "0.3240887\n",
      "0.5764012\n",
      "0.81000537\n",
      "1.2826822\n",
      "0.49363825\n",
      "1.51559\n",
      "1.4081206\n",
      "0.53923637\n",
      "1.3849823\n",
      "1.2069544\n",
      "0.6588366\n",
      "1.5067456\n",
      "0.48296303\n",
      "1.0634134\n",
      "1.0705358\n",
      "0.56409585\n",
      "0.90437514\n",
      "0.7632713\n",
      "1.2934048\n",
      "0.4948115\n",
      "1.419717\n",
      "0.33459085\n",
      "0.5047251\n",
      "1.2036328\n",
      "1.2856714\n",
      "1.5423262\n",
      "1.1929783\n",
      "0.38338417\n",
      "0.33154497\n",
      "1.1938854\n",
      "1.0432955\n",
      "1.3154349\n",
      "0.76719\n",
      "1.1854073\n",
      "1.0307071\n",
      "1.446638\n",
      "0.8310849\n",
      "1.0115628\n",
      "0.5468562\n",
      "0.3304044\n",
      "1.2866547\n",
      "1.051249\n",
      "0.49243927\n",
      "0.49949867\n",
      "1.3017304\n",
      "0.74384815\n",
      "0.9084649\n",
      "1.3087587\n",
      "0.7803264\n",
      "0.3564363\n",
      "1.1917262\n",
      "0.4935666\n",
      "1.478056\n",
      "0.49284443\n",
      "1.1825109\n",
      "0.66730714\n",
      "0.77416146\n",
      "1.418406\n",
      "1.0379403\n",
      "1.3985262\n",
      "1.3834565\n",
      "0.5815583\n",
      "1.4499168\n",
      "0.58860075\n",
      "1.5298479\n",
      "0.53969216\n",
      "0.87132555\n",
      "1.4400549\n",
      "0.6118106\n",
      "0.31303844\n",
      "0.4791881\n",
      "0.8520243\n",
      "0.6078232\n",
      "1.4227141\n",
      "0.32333562\n",
      "0.54800427\n",
      "0.546114\n",
      "1.2740122\n",
      "0.31771025\n",
      "0.53651977\n",
      "1.0636617\n",
      "1.5722768\n",
      "1.0382144\n",
      "0.46740907\n",
      "0.38331994\n",
      "1.5168049\n",
      "1.2305924\n",
      "0.8054674\n",
      "0.5435303\n",
      "0.605187\n",
      "0.5180225\n",
      "0.790039\n",
      "0.8989605\n",
      "0.5727541\n",
      "0.5659546\n",
      "0.5348782\n",
      "0.5422401\n",
      "1.0450145\n",
      "0.7927993\n",
      "0.6413164\n",
      "0.5856336\n",
      "1.3038439\n",
      "0.58744425\n",
      "0.4907547\n",
      "1.223934\n",
      "1.5180657\n",
      "1.8390085\n",
      "0.4996578\n",
      "1.4143052\n",
      "0.37887806\n",
      "1.2894247\n",
      "0.87804705\n",
      "0.87195855\n",
      "0.6298524\n",
      "0.29782024\n",
      "0.5422019\n",
      "0.57922864\n",
      "0.39789772\n",
      "0.8827968\n",
      "1.4169259\n",
      "1.5282465\n",
      "1.2724859\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model_result)):\n",
    "    print(model_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
